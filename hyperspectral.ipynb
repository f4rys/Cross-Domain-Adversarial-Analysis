{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cefd269b",
   "metadata": {},
   "source": [
    "## Adversarial attacks - hyperspectral model HybridSN\n",
    "This notebook demonstrates adversarial attacks on the trained HybridSN model using the Indian Pines (IP) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b36be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.io import loadmat\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from attacks.fgsm import FGSM\n",
    "from attacks.pgd import PGD\n",
    "from attacks.cw import CW\n",
    "from attacks.deepfool import DeepFool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # How many images to process at once\n",
    "NUM_IMAGES = 256 # How many images to process in total\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check device\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf50ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_IMAGES > 10249:\n",
    "    raise ValueError(\"NUM_IMAGES must be less than or equal to 10249, the number of images in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c642be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IP dataset and preprocess (PCA, patch extraction)\n",
    "def load_ip_data():\n",
    "    data_path = os.path.join(os.getcwd(), 'data', 'IndianPines')\n",
    "    data = loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "    labels = loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    # PCA\n",
    "    pca = PCA(n_components=15, whiten=True)\n",
    "    newX = np.reshape(data, (-1, data.shape[2]))\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (data.shape[0], data.shape[1], 15))\n",
    "    return newX, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchSet(Dataset):\n",
    "    def __init__(self, data, gt, patch_size):\n",
    "        self.patch_size = patch_size\n",
    "        p = self.patch_size // 2\n",
    "        self.data = np.pad(data, ((p,p),(p,p),(0,0)), 'constant')\n",
    "        self.label = np.pad(gt, (p,p), 'constant')\n",
    "        x_pos, y_pos = np.nonzero(gt)\n",
    "        x_pos, y_pos = x_pos + p, y_pos + p\n",
    "        self.indices = np.array([(x,y) for x,y in zip(x_pos, y_pos)])\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.indices[i]\n",
    "        x1, y1 = x - self.patch_size // 2, y - self.patch_size // 2\n",
    "        x2, y2 = x1 + self.patch_size, y1 + self.patch_size\n",
    "        data = self.data[x1:x2, y1:y2]\n",
    "        label = self.label[x, y]\n",
    "        data = np.asarray(data, dtype='float32').transpose((2, 0, 1))\n",
    "        label = np.asarray(label, dtype='int64')\n",
    "        return torch.from_numpy(data), torch.from_numpy(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defination of HybridSN\n",
    "class HybridSN(nn.Module):\n",
    "    def __init__(self, in_chs, patch_size, class_nums):\n",
    "        super().__init__()\n",
    "        self.in_chs = in_chs\n",
    "        self.patch_size = patch_size\n",
    "        self.conv1 = nn.Sequential(\n",
    "                    nn.Conv3d(in_channels=1,out_channels=8,kernel_size=(7, 3, 3)),\n",
    "                    nn.ReLU(inplace=True))\n",
    "        self.conv2 = nn.Sequential(\n",
    "                    nn.Conv3d(in_channels=8,out_channels=16,kernel_size=(5, 3, 3)),\n",
    "                    nn.ReLU(inplace=True))\n",
    "        self.conv3 = nn.Sequential(\n",
    "                    nn.Conv3d(in_channels=16,out_channels=32,kernel_size=(3, 3, 3)),\n",
    "                    nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.x1_shape = self.get_shape_after_3dconv()\n",
    "        # print(self.x1_shape)\n",
    "        self.conv4 = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=self.x1_shape[1]*self.x1_shape[2],out_channels=64,kernel_size=(3, 3)),\n",
    "                    nn.ReLU(inplace=True))\n",
    "        self.x2_shape = self.get_shape_after_2dconv()\n",
    "        # print(self.x2_shape)\n",
    "        self.dense1 = nn.Sequential(\n",
    "                    nn.Linear(self.x2_shape,256),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Dropout(p=0.4))\n",
    "        \n",
    "        self.dense2 = nn.Sequential(\n",
    "                    nn.Linear(256,128),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Dropout(p=0.4))\n",
    "        \n",
    "        self.dense3 = nn.Sequential(\n",
    "                    nn.Linear(128,class_nums)\n",
    "                   )\n",
    "    \n",
    "    def get_shape_after_2dconv(self):\n",
    "        x = torch.zeros((1, self.x1_shape[1]*self.x1_shape[2], self.x1_shape[3], self.x1_shape[4]))\n",
    "        with torch.no_grad():\n",
    "            x = self.conv4(x)\n",
    "            print\n",
    "        return x.shape[1]*x.shape[2]*x.shape[3]\n",
    "    \n",
    "    def get_shape_after_3dconv(self):\n",
    "        x = torch.zeros((1, 1, self.in_chs, self.patch_size, self.patch_size))\n",
    "        with torch.no_grad():\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.conv3(x)\n",
    "        return x.shape\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = X.unsqueeze(1)\n",
    "        x = self.conv1(X)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.shape[0],x.shape[1]*x.shape[2],x.shape[3],x.shape[4])\n",
    "        # print(x.shape)\n",
    "        x = self.conv4(x)\n",
    "        x = x.contiguous().view(x.shape[0], -1)\n",
    "        # print(x.shape)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        out = self.dense3(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c62be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PCA = 15\n",
    "PATCH_SIZE = 25\n",
    "NUM_CLASS = 16\n",
    "\n",
    "model = HybridSN(N_PCA, PATCH_SIZE, class_nums=NUM_CLASS)\n",
    "model.load_state_dict(torch.load('model/ip_final_weights.pth', map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Prepare test data\n",
    "ip_data, ip_labels = load_ip_data()\n",
    "test_gt = (ip_labels > 0).astype(np.int64) * ip_labels\n",
    "test_data = PatchSet(ip_data, test_gt, PATCH_SIZE)\n",
    "test_data = torch.utils.data.Subset(test_data, range(NUM_IMAGES))\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to hold results\n",
    "perturbation_results = {}\n",
    "attack_times = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2283c06",
   "metadata": {},
   "source": [
    "## Fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM\n",
    "FGSM_EPSILON = 0.01\n",
    "\n",
    "# PGD\n",
    "PGD_EPSILON = 0.01\n",
    "PGD_ALPHA = 0.003\n",
    "PGD_STEPS = 1\n",
    "\n",
    "# CW\n",
    "CW_C = 5\n",
    "CW_KAPPA = 0\n",
    "CW_STEPS = 20\n",
    "CW_LR = 0.03\n",
    "\n",
    "# DeepFool\n",
    "DF_STEPS = 1\n",
    "DF_OVERSHOOT = 0.01\n",
    "NUM_CLASSES = NUM_CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2360f86",
   "metadata": {},
   "source": [
    "## FGSM Attack\n",
    "Apply FGSM to the test set and evaluate the model's accuracy on adversarial examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm = FGSM(model, eps=FGSM_EPSILON, clip_min=0.0, clip_max=1.0)\n",
    "fgsm_acc = None\n",
    "correct = 0\n",
    "total = 0\n",
    "fgsm_l2 = []\n",
    "fgsm_linf = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(DEVICE), (target-1).to(DEVICE)\n",
    "    adv_data = fgsm(data, target)\n",
    "    output = model(adv_data)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct += (pred == target).sum().item()\n",
    "    total += target.size(0)\n",
    "    perturb = (adv_data - data).view(data.size(0), -1)\n",
    "    fgsm_l2.extend(torch.norm(perturb, p=2, dim=1).cpu().numpy())\n",
    "    fgsm_linf.extend(torch.norm(perturb, p=float('inf'), dim=1).cpu().numpy())\n",
    "\n",
    "fgsm_acc = correct / total\n",
    "perturbation_results['FGSM'] = (np.mean(fgsm_l2), np.mean(fgsm_linf))\n",
    "attack_times['FGSM'] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53454b",
   "metadata": {},
   "source": [
    "## PGD Attack\n",
    "Apply PGD to the test set and evaluate the model's accuracy on adversarial examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd = PGD(model, eps=PGD_EPSILON, alpha=PGD_ALPHA, steps=PGD_STEPS, clip_min=0.0, clip_max=1.0)\n",
    "pgd_acc = None\n",
    "correct = 0\n",
    "total = 0\n",
    "pgd_l2 = []\n",
    "pgd_linf = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(DEVICE), (target-1).to(DEVICE)\n",
    "    adv_data = pgd(data, target)\n",
    "    output = model(adv_data)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct += (pred == target).sum().item()\n",
    "    total += target.size(0)\n",
    "    perturb = (adv_data - data).view(data.size(0), -1)\n",
    "    pgd_l2.extend(torch.norm(perturb, p=2, dim=1).cpu().numpy())\n",
    "    pgd_linf.extend(torch.norm(perturb, p=float('inf'), dim=1).cpu().numpy())\n",
    "\n",
    "pgd_acc = correct / total\n",
    "perturbation_results['PGD'] = (np.mean(pgd_l2), np.mean(pgd_linf))\n",
    "attack_times['PGD'] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c722483",
   "metadata": {},
   "source": [
    "## CW Attack\n",
    "Apply CW to the test set and evaluate the model's accuracy on adversarial examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334def26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = CW(model, c=CW_C, kappa=CW_KAPPA, steps=CW_STEPS, lr=CW_LR, clip_min=0.0, clip_max=1.0)\n",
    "df_cw_acc = None\n",
    "correct = 0\n",
    "total = 0\n",
    "cw_l2 = []\n",
    "cw_linf = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(DEVICE), (target-1).to(DEVICE)\n",
    "    adv_data = cw(data, target)\n",
    "    output = model(adv_data)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct += (pred == target).sum().item()\n",
    "    total += target.size(0)\n",
    "    perturb = (adv_data - data).view(data.size(0), -1)\n",
    "    cw_l2.extend(torch.norm(perturb, p=2, dim=1).cpu().numpy())\n",
    "    cw_linf.extend(torch.norm(perturb, p=float('inf'), dim=1).cpu().numpy())\n",
    "\n",
    "df_cw_acc = correct / total\n",
    "perturbation_results['CW'] = (np.mean(cw_l2), np.mean(cw_linf))\n",
    "attack_times['CW'] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02baa01f",
   "metadata": {},
   "source": [
    "## DeepFool Attack\n",
    "Apply DeepFool to the test set and evaluate the model's accuracy on adversarial examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfool = DeepFool(model, steps=DF_STEPS, overshoot=DF_OVERSHOOT, num_classes=NUM_CLASSES, clip_min=0.0, clip_max=1.0)\n",
    "df_deepfool_acc = None\n",
    "correct = 0\n",
    "total = 0\n",
    "deepfool_l2 = []\n",
    "deepfool_linf = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(DEVICE), (target-1).to(DEVICE)\n",
    "    adv_data = deepfool(data, target)\n",
    "    output = model(adv_data)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct += (pred == target).sum().item()\n",
    "    total += target.size(0)\n",
    "    perturb = (adv_data - data).view(data.size(0), -1)\n",
    "    deepfool_l2.extend(torch.norm(perturb, p=2, dim=1).cpu().numpy())\n",
    "    deepfool_linf.extend(torch.norm(perturb, p=float('inf'), dim=1).cpu().numpy())\n",
    "\n",
    "df_deepfool_acc = correct / total\n",
    "perturbation_results['DeepFool'] = (np.mean(deepfool_l2), np.mean(deepfool_linf))\n",
    "attack_times['DeepFool'] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878cb4c2",
   "metadata": {},
   "source": [
    "## Clean accuracy\n",
    "Calculate accuracy on clean images for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute clean accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(DEVICE), (target-1).to(DEVICE)\n",
    "    output = model(data)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct += (pred == target).sum().item()\n",
    "    total += target.size(0)\n",
    "\n",
    "clean_acc = correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a1f99a",
   "metadata": {},
   "source": [
    "## Results\n",
    "Display accuracies of FGSM, PGD, CW, DeepFool attacks versus clean accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram with y-axis in percent and value labels\n",
    "labels = ['Clean', 'FGSM', 'PGD', 'CW', 'DeepFool']\n",
    "accuracies = [clean_acc, fgsm_acc, pgd_acc, df_cw_acc, df_deepfool_acc]\n",
    "percentages = [a * 100 for a in accuracies]\n",
    "bars = plt.bar(labels, percentages, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
    "plt.ylim(0, 110)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('HybridSN Accuracy: Clean vs. Adversarial Attacks')\n",
    "\n",
    "# Add value labels\n",
    "for bar, pct in zip(bars, percentages):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 2, f'{pct:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Clean Accuracy: {clean_acc:.4f}')\n",
    "print(f'FGSM Accuracy: {fgsm_acc:.4f}')\n",
    "print(f'PGD Accuracy: {pgd_acc:.4f}')\n",
    "print(f'CW Accuracy: {df_cw_acc:.4f}')\n",
    "print(f'DeepFool Accuracy: {df_deepfool_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfaa504",
   "metadata": {},
   "source": [
    "## Execution time\n",
    "Plot execution time for each attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79995cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(attack_times.keys())\n",
    "times = [attack_times[k] for k in labels]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(labels, times, color=['#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Execution Time of Adversarial Attacks')\n",
    "\n",
    "plt.ylim(0, max(times) * 1.1)\n",
    "\n",
    "# Add value labels\n",
    "for bar, t in zip(bars, times):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.05, f'{t:.2f}s', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba3f284",
   "metadata": {},
   "source": [
    "## Calculate L2, L-inf norms\n",
    "Calculate and compare average perturbation magnitudes for each attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dfb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print('Average perturbation magnitude (L2 norm, Linf norm):')\n",
    "for attack, (l2, linf) in perturbation_results.items():\n",
    "    print(f'{attack}: L2 = {l2:.4f}, Linf = {linf:.4f}')\n",
    "\n",
    "# Plot bar chart for L2 and Linf\n",
    "labels = list(perturbation_results.keys())\n",
    "l2_vals = [perturbation_results[k][0] for k in labels]\n",
    "linf_vals = [perturbation_results[k][1] for k in labels]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, l2_vals, width, label='L2 norm')\n",
    "rects2 = ax.bar(x + width/2, linf_vals, width, label='Linf norm')\n",
    "\n",
    "ax.set_ylabel('Average Perturbation')\n",
    "ax.set_title('Average Perturbation Magnitude by Attack')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "max_val = max(max(l2_vals), max(linf_vals))\n",
    "ax.set_ylim(0, max_val * 1.1)\n",
    "\n",
    "for rect in rects1:\n",
    "    height = rect.get_height()\n",
    "    ax.annotate(f'{height:.2f}',\n",
    "                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "for rect in rects2:\n",
    "    height = rect.get_height()\n",
    "    ax.annotate(f'{height:.2f}',\n",
    "                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HybridSN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
